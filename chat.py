import logging
import os

from dotenv import load_dotenv
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_litellm import ChatLiteLLM
from langchain_neo4j import Neo4jVector
from rich.logging import RichHandler

# è®¾ç½®æ—¥å¿—è®°å½•
logger = logging.getLogger("chat")
logging.basicConfig(
    level=logging.INFO,
    format="%(message)s",
    datefmt="[%X]",
    handlers=[RichHandler(rich_tracebacks=True)],
)

# ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®
load_dotenv()

# åˆå§‹åŒ– LLM
llm = ChatLiteLLM(
    model="deepseek/deepseek-chat",
    temperature=0.7,
    api_key=os.getenv("API_KEY", "enter_your_api_key_in_.env"),
)


embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")

neo4j_vector = Neo4jVector.from_existing_graph(
    embedding=embeddings,
    node_label="Document",
    embedding_node_property="embedding",
    text_node_properties=["name", "description"],
    url=os.getenv("NEO4J_URL", "enter_your_neo4j_url_in_.env"),
    username=os.getenv("NEO4J_USER", "enter_your_neo4j_username_in_.env"),
    password=os.getenv("NEO4J_PASSWORD", "enter_your_neo4j_password_in_.env"),
)


def retrieve_from_neo4j(query: str, top_k: int = 5):
    """ä» Neo4j æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡"""
    try:
        logger.info(f"ğŸ” æ­£åœ¨æ£€ç´¢ä¸é—®é¢˜ç›¸å…³çš„çŸ¥è¯†: {query}")
        results = neo4j_vector.similarity_search(query, k=top_k)
        if not results:
            return []

        contexts = [doc.page_content for doc in results]
        logger.info(f"âœ… æ£€ç´¢åˆ° {len(contexts)} æ¡ç›¸å…³çŸ¥è¯†")
        logger.info(f"ğŸ”— ç›¸å…³çŸ¥è¯†å†…å®¹: {contexts}")
        return contexts
    except Exception as e:
        logger.error(f"âŒ Neo4j æ£€ç´¢å¤±è´¥: {e}")
        return []


def rag_chat(query: str):
    """åŸºäº RAG çš„é—®ç­”æµç¨‹"""
    # æ£€ç´¢ä¸Šä¸‹æ–‡
    context_list = retrieve_from_neo4j(query)
    if not context_list:
        return "æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†ï¼Œè¯·æ¢ä¸ªé—®é¢˜è¯•è¯•ï½"

    # æ‹¼æ¥ä¸Šä¸‹æ–‡
    context_str = "\n".join(f"- {c}" for c in context_list)

    # æ„å»ºæç¤ºè¯
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†ä¸°å¯Œçš„AIåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ä»¥ä¸‹èƒŒæ™¯çŸ¥è¯†å›ç­”é—®é¢˜ã€‚

    èƒŒæ™¯çŸ¥è¯†:
    {context_str}

    é—®é¢˜:
    {query}

    è¯·ç”¨ç®€æ´ã€å‡†ç¡®çš„è¯­è¨€å›ç­”:
    """

    # è°ƒç”¨ LLM
    try:
        logger.info("ğŸ¤– æ­£åœ¨ç”Ÿæˆå›ç­”...")
        response = llm.invoke(prompt)
        return str(response).strip()
    except Exception as e:
        logger.error(f"âŒ LLM è°ƒç”¨å¤±è´¥: {e}")
        return "ç”Ÿæˆå›ç­”å¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚"


def main():
    """ä¸»äº¤äº’å¾ªç¯"""
    logger.info("ğŸš€ RAG é—®ç­”ç³»ç»Ÿå¯åŠ¨ï¼Œè¾“å…¥ 'exit' é€€å‡º")
    while True:
        user_input = input("\nè¯·è¾“å…¥é—®é¢˜: ").strip()
        if user_input.lower() in ["exit", "quit"]:
            logger.info("ğŸ‘‹ å·²é€€å‡º RAG é—®ç­”ç³»ç»Ÿ")
            break
        answer = rag_chat(user_input)
        print(f"\nğŸ¤– å›ç­”: {answer}")


if __name__ == "__main__":
    main()
