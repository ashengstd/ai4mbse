import logging
from typing import Optional

from langchain.prompts import PromptTemplate
from langchain_litellm import ChatLiteLLM

from chat.template import entity_prompt_template
from controller.graph import Neo4jGraphController


# --- å®ä½“æå–å‡½æ•° ---
def extract_entities(
    llm: ChatLiteLLM, question: str, logger: logging.Logger
) -> list[str]:
    """
    ä½¿ç”¨ LLM ä»é—®é¢˜ä¸­æå–å®ä½“åˆ—è¡¨ã€‚
    Args:
        question (str): ç”¨æˆ·æé—®
    Returns:
        list: æå–åˆ°çš„å®ä½“åˆ—è¡¨
    ä¾‹å¦‚ï¼š['æ¯”å°”Â·ç›–èŒ¨', 'è‹¹æœå…¬å¸', 'é©¬æ–¯å…‹', 'é£æœº']
    """
    logger.info(f"ğŸ§  æ­£åœ¨æå–å®ä½“: {question}")
    entities_text = llm.invoke(
        PromptTemplate(
            input_variables=["question"], template=entity_prompt_template
        ).format(question=question)
    ).content
    if not isinstance(entities_text, str):
        logger.error("âŒ å®ä½“æå–ç»“æœä¸æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œè¯·æ£€æŸ¥ LLM å“åº”æ ¼å¼ã€‚")
        return []
    entities_text_list = entities_text.split(",")
    entities = [
        e.strip().strip("'").strip('"') for e in entities_text_list if e.strip()
    ]
    logger.info(f"âœ… æå–åˆ°å®ä½“: {entities}")
    return entities


# --- é—®é¢˜å¤„ç†ä¸»æµç¨‹ ---
def query_by_subgraphs(
    llm: ChatLiteLLM,
    graph_controller: Neo4jGraphController,
    logger: logging.Logger,
    question: str,
    depth=2,
    limit=20,
) -> Optional[str]:
    # 1. æå–å®ä½“
    entities = extract_entities(llm=llm, question=question, logger=logger)
    if not entities:
        logger.warning("âš ï¸ æ²¡æœ‰æå–åˆ°å®ä½“ï¼Œæ— æ³•è¿›è¡Œå­å›¾æŸ¥è¯¢ã€‚")
        return None

    # 2.ä¸æ•°æ®åº“ä¸­çš„å®ä½“è¿›è¡Œæ£€ç´¢
    logger.info(f"ğŸ” æŸ¥è¯¢å®ä½“: {entities}")
    likely_entities = graph_controller.search_likely_entities(entities)
    if not likely_entities:
        logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å®ä½“ï¼Œæ— æ³•è¿›è¡Œå­å›¾æŸ¥è¯¢ã€‚")
        return None
    logger.info(f"âœ… åŒ¹é…åˆ°çš„å®ä½“: {likely_entities}")

    # 3. æŸ¥è¯¢å­å›¾
    subgraphs = graph_controller.query_subgraph(
        likely_entities, depth=depth, limit=limit
    )
    if not subgraphs:
        logger.warning("âš ï¸ å­å›¾æŸ¥è¯¢ç»“æœä¸ºç©ºã€‚")
        return None
    logger.info(f"ğŸŒŸ å­å›¾æŸ¥è¯¢æˆåŠŸï¼Œç»“æœæ•°é‡: {len(subgraphs)}ï¼Œå†…å®¹ä¸ºï¼š{subgraphs}")

    # 4. å†æ¬¡æ ¼å¼åŒ–é—®é¢˜
    prompt = PromptTemplate(
        input_variables=["question", "subgraph"],
        template="è¯·æ ¹æ®ä»¥ä¸‹å­å›¾ä¿¡æ¯å›ç­”é—®é¢˜ï¼š\n\n{question}\n\nå­å›¾ä¿¡æ¯ï¼š{subgraph}",
    )
    question = prompt.format(question=question, subgraph=subgraphs)
    answer = llm.invoke(question).content
    logger.info(f"ğŸ“ æ ¼å¼åŒ–åçš„é—®é¢˜: {question}")
    logger.info(f"ğŸ’¡ å›ç­”: {answer}")
    return answer
